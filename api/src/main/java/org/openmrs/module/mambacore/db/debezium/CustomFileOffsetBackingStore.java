package com.ayinza.util.debezium.application.service;

import jakarta.inject.Inject;
import org.apache.kafka.connect.json.JsonConverter;
import org.apache.kafka.connect.json.JsonConverterConfig;
import org.apache.kafka.connect.storage.FileOffsetBackingStore;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Collections;

/**
 * Custom {@link FileOffsetBackingStore} that only saves the offset if no exception was encountered
 * while processing a source record read by debezium from the MySQL binlog to ensure no binlog entry
 * goes unprocessed.
 */
public class CustomFileOffsetBackingStore extends FileOffsetBackingStore {

    protected static final Logger log = LoggerFactory.getLogger(CustomFileOffsetBackingStore.class);
    private static final JsonConverter KEY_CONVERTER = new JsonConverter();
    private static boolean disabled = false;

    @Inject
    private OffsetUtils offsetUtils;

    public CustomFileOffsetBackingStore() {
        super(KEY_CONVERTER);
        KEY_CONVERTER.configure(Collections.singletonMap(JsonConverterConfig.SCHEMAS_ENABLE_CONFIG, "false"), true);
    }

    /**
     * Disables offset storage
     */
    public static void disable() {
        disabled = true;
        log.debug("Disabled saving of offsets");
    }

    /**
     * Re-enables offset storage
     */
    public static void reset() {
        disabled = false;
    }

    /**
     * @see FileOffsetBackingStore#save()
     */
    @Override
    protected void save() {

        synchronized (CustomFileOffsetBackingStore.class) {

            if (disabled) {
                log.warn("Skipping saving of offset because an error was encountered while processing a change event");
                return;
            }
            log.debug("Saving binlog offset");
            super.save();
        }
    }

    /**
     * @see FileOffsetBackingStore#start()
     */
    @Override
    public synchronized void start() {

        doStart();

        try {
            //The offset file structure changed from that generated by previous versions therefore, we need to
            //transform any existing offset file to match the new structure otherwise remote sites will lose any
            //events that are recorded between pre-upgrade and post-upgrade application runs of the sender.
            offsetUtils.transformOffsetIfNecessary(data);
        } catch (Exception e) {
            throw new RuntimeException("An error occurred while verifying the existing debezium offset file data", e);
        }
    }

    protected void doStart() {
        super.start();
    }
}
